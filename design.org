#+title: Torrent: A Rust-based Emacs Lisp Compiler/Runtime
#+author: dwuggh
#+LATEX_CLASS: koma-article
#+LATEX_CLASS_OPTIONS: [11pt,final]


First, I want to say I am not a professional computer science researcher or programmer, and I did not major in CS. I may make fundamental, conceptual mistakes because of ignorance—please feel free to correct me when I am wrong.

Second, heavily inspired by [[https://github.com/CeleritasCelery/rune][Rune]], a fantastic project, I consider *Torrent* the "anaphoric counterpart" to Rune—that is, it intentionally adopts technologies that Rune does not use. I do not want the design to be similar; that would defeat the purpose. This project aims to explore other possibilities for a Rust‑based Emacs Lisp compiler until we have a usable one—or at least until I can use Lisp to write configs for other systems (for example, niri).

* Compiler Architecture
** Background
  Many dynamic languages compile to bytecode and interpret it in a bytecode VM. The most famous example is Java and the JVM. Bytecode provides excellent cross‑platform compatibility and fast startup. Sometimes that is not fast enough, and we want the ability to compile code to native machine instructions, usually by translating bytecode to platform‑specific ISAs. However, dynamic languages face challenges:

- symbols, functions, and variables may change at runtime, so we cannot always generate stable calls;
- variable types are often unknown in advance, which blocks many instruction‑level optimizations;
- ...

These problems arise from language flexibility. If we can "pin" aspects of the runtime, we can provide type information to the compiler and generate faster code. This is the idea of *Just‑In‑Time* (JIT) compilation. Fast JITs often perform type specialization, function inlining, and other techniques to make hot paths fast. We also need a way to invalidate compiled code when assumptions no longer hold; guard checks support this *optimization and de‑optimization* cycle.

Highly optimized runtimes often add an extra tier—a more aggressive JIT that spends more time compiling to get higher throughput. This *tiered JIT* approach is used by Google’s V8 and Mozilla’s SpiderMonkey.

There are also attempts to make AOT compilation fast [cite:@serranoJavaScriptAOTCompilation2018], but they require substantial static analysis.

** Bytecode VM
There are two common VM styles: **register VMs** and **stack VMs**. Stack VMs are most common; the JVM and CPython are examples. A stack VM retrieves operands from a runtime stack. A register VM, like a physical CPU, exposes a set of virtual registers and operates on them (but still uses a stack for calls). Lua 5.0 switched from a stack VM to a register VM [cite:@ierusalimschyImplementationLua50] [[https://github.com/MoarVM/MoarVM][MoarVM]]. The opcode sets differ, but translation between them is feasible. Research indicates that although stack VMs have denser bytecode, register VMs often execute fewer instructions and run faster [cite:@shiVirtualMachineShowdown].

Emacs Lisp uses a stack VM, and Rune provides a Rust implementation. In Torrent, I might add a register VM later. For now, the plan is to use a baseline JIT or AOT compiler instead of a bytecode interpreter. There is an old but interesting blog post arguing for this direction [cite:@UsingBytecodeWont]. However, few languages take this approach. As far as I know, Julia does not have a bytecode interpreter; it emits LLVM bitcode. In my brief experience (writing a surface‑code simulator), Julia’s compilation time was nearly unbearable, and at the time it lacked several language features (e.g., enums) and had buggy reloading. I eventually rewrote the project in Rust.

For Emacs Lisp, this approach still seems promising. Today most code ends up native‑compiled and users appear happy with that. Technically, most Emacs code does not change once loaded; only a small subset changes—for example, when modes advise functions, or when users debug Elisp, write configs, or develop packages. Most of the time, Emacs is used as an editor—a **tool** for editing files—so compile speed is less critical here.

For code generation I use [[https://cranelift.dev][Cranelift]] instead of LLVM. Cranelift’s single‑IR architecture yields excellent compile speed and sufficiently fast execution (around 15% slower than LLVM). I am therefore not concerned about compile time.

Rather than bytecode, I use a high‑level IR (HIR) to represent Elisp. It encodes special forms directly and performs simple lexical‑binding and closure analyses. I plan to adopt further optimizations following [cite:@serranoJavaScriptAOTCompilation2018].

An intriguing option is to serialize HIR as Lisp itself—i.e., use Elisp as the IR. This might or might not be useful. [[https://github.com/cisco/ChezScheme][ChezScheme]] may follow a similar idea: it performs many optimizations in Scheme; essentially a Scheme compiler written in Scheme that achieves great performance. I have not investigated this deeply yet, but it is certainly a project worth learning from.

To summarize, the current big picture is:

Emacs Lisp Source → HIR → Baseline JIT → Optimizing JIT

Only the baseline JIT has a naive implementation today.

* GC Design
  GC theory is vast; I can only summarize what I have read. My main reference is the GC handbook [cite:@jonesGarbageCollectionHandbook2023].

** Tracing GC vs Reference Counting GC
Rune’s design document claims reference counting is slow; that is not necessarily true. The two paradigms can be unified in theory [cite:@baconUnifiedTheoryGarbage]. In short, tracing GC finds *live* objects, while RC identifies *dead* ones. In practice, naive RC has pitfalls, but they can be addressed [cite:@jonesGarbageCollectionHandbook2023]. The main challenges are:

1. cycle detection, especially in concurrent settings;
2. write‑barrier overhead on the mutator.

Cycle collection is addressed by [cite:@baconConcurrentCycleCollection2001] and follow‑ups (see [cite:@jonesGarbageCollectionHandbook2023]). Barrier costs can be mitigated through **deferred reference counting** and **coalesced reference counting**; the latter is particularly powerful. We also have LXR [cite:@zhaoLowLatencyHighThroughputGarbage2022], a recent high‑performance RC GC.

** Rust implementations
[[https://github.com/maplant/scheme-rs][scheme-rs]] implements the Bacon–Rajan algorithm, which I initially copied. However, it does not adopt coalesced RC and uses Tokio channels to send mutation buffers immediately, adding overhead. On Fibonacci benchmarks, scheme‑rs performs poorly. I could not run flamegraph or perf with Tokio enabled, so I lack data, but I suspect the GC is the major factor.

Recently, a BFS‑based refinement of Bacon–Rajan was proposed [cite:@giallorenzoBreadthfirstCycleCollection2025], with a Rust implementation. I have not read the paper thoroughly yet.

[[[https://mmtk.io][MMTK](https://mmtk.io][MMTK)]] is a growing GC SDK in Rust. LXR [cite:@zhaoLowLatencyHighThroughputGarbage2022] is implemented on a separate MMTK branch; there are many divergent commits, so merging will take time. MMTK already provides a solid platform; my long‑term goal is to integrate with it.

* Lisp Object Representation
** Objects are tagged pointers
  I follow Rune’s approach: a shifting tagged pointer. Since most Elisp values are pointers and we are unlikely to do numeric‑heavy work, the tagging scheme is not performance‑critical. The current floating point implementation is incorrect; I am still deciding whether ~f32~ is sufficient. [[file:./src/core/tagged_ptr.rs][tagged_ptr.rs]] provides the tagged‑pointer interfaces; the abstraction seems sound.

** Ergonomics
Rune handles moving GC with a clever technique using Rust lifetimes [cite:@ImplementingSafeGarbage2022]. If I understand correctly, it pins objects on the stack during GC and relies on lifetime checks to prevent errors. In a JIT setting this no longer suffices; we need stack maps. Torrent uses a placeholder stack map for now while I investigate Cranelift’s API. [[https://bytecodealliance.zulipchat.com/#narrow/channel/217117-cranelift/topic/how.20to.20use.20stack.20map.20for.20GC/with/539611462][a question I asked]] and [[https://bytecodealliance.zulipchat.com/#narrow/channel/217117-cranelift/topic/Guidelines.20on.20marking.20stack.20map.20entries/with/540311697][another discussion]] provide guidance on retrieving stack maps in Cranelift.

For moving collectors, a forwarding pointer (e.g., ~Object::Indirect~) should suffice. I need to read more papers before committing; poor knowledge leads to poor design.

The [[https://docs.rs/inventory/latest/inventory/][inventory]] crate collects Rust subroutines, i.e., ~#[defun]~-marked functions. Rune uses ~build.rs~ for this, which is more limited and harder to maintain. This idea is also borrowed from scheme‑rs.

* Concurrency
Rune’s concurrency vision is described in this [[https://coredumped.dev/2022/05/19/a-vision-of-a-multi-threaded-emacs/][blog post]]. I currently know very little about concurrency, so I cannot offer strong opinions. Rune aims for Emacs compatibility; Torrent will feel free to diverge.

* UI
In my vision, the new emacs UI should not be limited to 2D scenes and text buffers. But there aren't much choice for rust's GUI toolkit. [[https://github.com/linebender/vello][vello]] and [[https://github.com/linebender/xilem][xilem]] is good and can be used, but vello uses compute shader pipeline, could be hard to integrate with other wgpu ecosystems. The viewmodel is proposed in [[https://github.com/CeleritasCelery/rune/pull/120][this pull request]], it obviously needs more careful considerations.

* Miscellaneous
** String representation
  Rune has a great analysis of Emacs strings. My use cases are UTF‑8 strings; the only reason for unibyte strings is passing binary data through FFI—better served by a dedicated type. An ~Arc<String>~ with ~Arc::make_mut~ should be adequate. We do not need to manage strings with the GC; Rust can manage them directly.

** Symbols and interning
Torrent uses ~lasso~ as the string interner. For AOT compilation, we may need to serialize/deserialize its state.

The current symbol representation is messy. There are two types: ~Ident~ (a ~lasso~ tag) and ~Symbol~ (a symbol‑table index plus a fallback tag). This is somewhat redundant; a more coherent design is needed.

* References
#+print_bibliography:
